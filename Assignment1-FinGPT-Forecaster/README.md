# STAT-GR5398-Spring-2025

# Assignment 1: Practical Application of FinGPT-Forecaster

# Overview

In this assignment, students will engage with the FinGPT-Forecaster, a state-of-the-art financial Large Language Model (LLM) designed to synthesize market insights and predict stock price movements. Students will gain hands-on experience in running LLM models, comparing different model architectures, and analyzing their outputs in the context of financial forecasting.

# Objectives
* Understand and execute the FinGPT-Forecaster code to generate market insights and stock predictions.
* Fine-tune and compare the performance of the Llama3-8b model with the DeepSeek-R1-Distill-Llama-8B model in terms of accuracy, efficiency, and output quality.
* Analyze and interpret the results to understand the practical implications of using different LLMs in financial forecasting.

# Tasks
1.	Run the FinGPT-Forecaster Model
* Set up and execute the FinGPT-Forecaster code using provided datasets.
* Document the process and any issues encountered during the execution.
2.	Model Comparison
* Load, run, and LoRA fine-tune both the Llama3-8b and DeepSeek-R1-Distill-Llama-8B models.
* Use the same input data for both models to ensure a fair comparison of results.
3.	Results Analysis
* Evaluate and compare the models based on predefined metrics such as predictive accuracy and response time.
* Prepare a report summarizing the findings, including visualizations of performance metrics and qualitative assessments of the output text.

# Learning Outcomes
By the end of this project, you will have gained practical experience in:
* Working with large language models in a specialized financial domain.
* Applying LLM techniques such as LoRA for efficient model fine-tuning.
* Analyzing and incorporating financial market data into AI workflows.
* Developing an AI-driven solution for real-world financial applications.


# Resources
* Code Repository: [FinGPT-Forecaster](https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster)
* Data: [Dow30](https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405)
* Base Model: [llama-3.1-8b](https://huggingface.co/meta-llama/Llama-3.1-8B), [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)
* Medium Blog: [Medium Blog](https://medium.com/@ll3713/the-road-to-fingpt-instructive-fine-tuned-market-forecaster-cfe7cbf9038b)
* Demo Platform: [Demo on HuggingFace](https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster)
* GPU Resources: Find a GPU service by yourself like Google Colab Pro ($10/month) for model training and development.

# Submission Requirements
* Write a Medium Blog that contains:
1. Setup and execution process descriptions.
2. Comparative analysis of the two models.
3. Visuals illustrating key findings.
4. Conclusion discussing the potential implications of the results in real-world financial applications.

# Evaluation Criteria
1. Accuracy of execution.
2. Depth of analysis in comparing the models.
3. Clarity and professionalism in reporting.

This assignment is designed to introduce students to the complexities of working with large-scale AI models in finance and to foster a practical understanding of how different AI technologies can impact financial analysis outcomes.